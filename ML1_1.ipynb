{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqFyzPDuFDvI"
   },
   "source": [
    "#**Первое занятие по PyTorch**\n",
    "\n",
    "Изучаем основные понятия и три ключевых пакета PyTorch, разбираемся, как формируется стандартный, универсальный алгоритм построения и анализа модели.\n",
    "\n",
    "Этот алгоритм вы сможете сразу использовать для проверки самых разных гипотез.\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fI4Zv-dtka20"
   },
   "source": [
    "\n",
    "*Дискламер: местами будут использоваться явные англицизмы -- чтобы быть в курсе, довольно часто они используются в тематических обсуждениях на русскоязычных форумах, и более компактны и наглядны.*\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Параллельно очень рекомендую к прочтению эту серию статей (перевод книги Майкла Нильсена \"Neural Networks and Deep Learning\")**\n",
    "https://habr.com/ru/post/463171/\n",
    "\n",
    "В ней подробно рассматривается вся базовая теория нейронных сетей и глубокого обучения.\n",
    "\n",
    "---\n",
    "\n",
    "##**Простая линейная регрессия**\n",
    "\n",
    "Есть простая линейная функция,  \n",
    "\n",
    "`y = 1 + 2 * x + шум`\n",
    "\n",
    "которая в контексте машинного обучения трактуется как прогнозирование некоторых результатов.\n",
    "\n",
    "x -- это **входные данные, признаки (features)**;\n",
    "y -- это **прогноз**.\n",
    "\n",
    "Например, если автомобиль едет с линейной скоростью, то пройденное им расстояние зависит от времени езды. В данных из реальной жизни в такой зависимости всегда будет шум -- скорость всё время немножечко плавает, возможны остановки на светофорах и т. д.\n",
    "\n",
    "Принципиальный момент. Чем вообще мы занимаемся?\n",
    "\n",
    "В нашей функции есть два коэффициента 1 и 2, или в общем случае\n",
    "\n",
    "`y = a + b * x`\n",
    "\n",
    "это коэффициенты (**параметры**) a и b, которые ещё называются **метки (labels)**.\n",
    "\n",
    "Про наши данные (например, набор пар значений \"время - расстояние\") мы знаем только, что они с большой вероятностью моделируются подобной линейной регрессией. То есть то, что нам надо найти -- это такие a и b, что соответствующая функция будет выдавать значения, как можно более близкие к обучающим.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25-CG5zmmtya"
   },
   "source": [
    "##**Немного теории: градиентный спуск**\n",
    "\n",
    "**Градиент (gradient)** -- это частная производная (производная по одной  конкретной переменной).\n",
    "\n",
    "*Кто не помнит школьный курс математики, производная -- это просто скорость изменения чего-то. Например, если вы едете с фиксированной скоростью, она не меняется, то и производная её (ускорение) будет равно нулю. А если скорость всё время растёт, то и градиент (ускорение) будет больше нуля, и тем он будет больше, чем сильнее увеличивается скорость.*\n",
    "\n",
    "В общем случае модель включает в себя множество параметров (скорость автомобиля -- это функция от множества критериев), и градиент показывает, как сильно меняется (со временем например) какой-то один конкретный параметр (считаем частную производную по этому параметру), подразумевая, что остальные если и меняются, то незначительно.\n",
    "\n",
    "**Лосс (loss)** -- ошибка, погрешность (например, среднеквадратическая ошибка).\n",
    "\n",
    "Оптимизационный механизм, отыскивающий нужные нам коэффициенты, называется \"**градиентный спуск**\" (подобных алгоритмов много). Его работа складывается из четырёх шагов.\n",
    "\n",
    "1) считаем лосс (стратегически стремимся к его минимизации).\n",
    "\n",
    "2) вычисляем градиенты.\n",
    "\n",
    "У нас в модели, как уже говорилось, есть два параметра a и b, для которых мы должны считать градиенты. Мы хотим определить, как будет меняться лосс при изменении каждого из этих параметров.\n",
    "\n",
    "3) обновляем параметры. Так как мы хотим минимизировать лосс, то градиенты берутся с обратным знаком, и учитывается также коэффициент скорости обучения.\n",
    "\n",
    "**Скорость обучения (learning rate)** -- некоторый коэффициент, который учитывается при изменении параметров в градиентном спуске.\n",
    "\n",
    "4) при необходимости проверяем что получилось, и переходим к п.1.\n",
    "\n",
    "Такой цикл из четырёх шагов называется **эпоха (epoch)**.\n",
    "Эпоха -- один цикл оптимизации (например, шаг градиентного спуска), когда была пересчитана каждая точка выборки.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZht9-DMpNmk"
   },
   "source": [
    "##**Градиентный спуск на базе NumPy**\n",
    "\n",
    "Реализуем сперва градиентный спуск классическим способом: только с помощью стандартной библиотеки численных методов NumPy.\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zL87rRR0TJeE"
   },
   "source": [
    "Подробное введение в линейную алгебру и NumPy для начинающих:\n",
    "\n",
    "https://github.com/DLSchool/dlschool/tree/master/02.%20Linear%20Algebra%2C%20Numpy\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bsd8wI9uUVDY"
   },
   "source": [
    "Введение в Matplotlib (рисуем графики):\n",
    "\n",
    "https://github.com/DLSchool/dlschool/tree/master/03.%20Pandas%2C%20Matplotlib%2C%20ML%20basics\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1_wBE0WU1Z8"
   },
   "source": [
    "Введение в линейные модели и градиентный спуск:\n",
    "\n",
    "https://github.com/DLSchool/dlschool/tree/master/04.%20Linear%20Models\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TsY44JTKBhQA"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "# оригинал\n",
    "# https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# инициализация повторяемой последовательности случайных чисел\n",
    "np.random.seed(42)\n",
    "\n",
    "# создаём np-массив из 100 случайных чисел в диапазоне 0..1\n",
    "sz = 100\n",
    "x = np.random.rand(sz, 1)\n",
    "\n",
    "# строим функцию y = f(x) и добавляем немного гауссова шума\n",
    "y = 1 + 2 * x + 0.1 * np.random.randn(sz, 1)\n",
    "\n",
    "# формируем индексы от 0 до 99\n",
    "idx = np.arange(sz)\n",
    "# случайно их тасуем\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "\n",
    "# первые 80 случайных индексов (значений x) используем для обучения\n",
    "sz80 = (int)(sz*0.8)\n",
    "train_idx = idx[:sz80]\n",
    "\n",
    "# оставшиеся 20 -- для валидации\n",
    "val_idx = idx[sz80:]\n",
    "\n",
    "# формируем наборы обучающих данных\n",
    "x_train, y_train = x[train_idx], y[train_idx]\n",
    "# и наборы для валидации\n",
    "x_val, y_val = x[val_idx], y[val_idx]\n",
    "\n",
    "# выводим на экран\n",
    "plt.scatter(x_train, y_train)\n",
    "plt.title('Обучающая выборка')\n",
    "plt.show()\n",
    "plt.scatter(x_val, y_val, color= \"red\")\n",
    "plt.title('Проверочная выборка')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GA1VF9YHUtmy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49671415] [-0.1382643]\n",
      "[1.02354094] [1.96896411]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# задаём начальные случайные значения коэффициентам линейной регрессии\n",
    "a = np.random.randn(1)\n",
    "b = np.random.randn(1)\n",
    "print(a,b)\n",
    "\n",
    "# скорость обучения\n",
    "lr = 0.1\n",
    "# количество эпох\n",
    "n_epochs = 1000\n",
    "\n",
    "# основной цикл\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    # рассчитываем результирующий массив с текущими коэффициентами a и b\n",
    "    # на основе обучающей выборки\n",
    "    yhat = a + b * x_train\n",
    "\n",
    "    # 1. определяем лосс\n",
    "    # сперва считаем отклонение нового результата от обучающего:\n",
    "    error = (y_train - yhat)\n",
    "    # и затем считаем среднеквадратическую ошибку:\n",
    "    loss = (error ** 2).mean()\n",
    "\n",
    "    # 2. считаем градиенты (вспоминая формулу производной)\n",
    "    # для коэффициента a\n",
    "    a_grad = -2 * error.mean()\n",
    "    # для коэффициента b\n",
    "    b_grad = -2 * (x_train * error).mean()\n",
    "\n",
    "    # 3. обновляем параметры, используя коэффициент скорости обучения,\n",
    "    # градиенты берём с обратным знаком\n",
    "    a = a - lr * a_grad\n",
    "    b = b - lr * b_grad\n",
    "print(a,b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y1qI2IV2pxyO"
   },
   "source": [
    "Итак, исходные коэффициенты были очень далеки от оригинальных:\n",
    "[0.49671415] [-0.1382643]\n",
    "\n",
    "Но итоговые результаты оказались весьма близки к ним:\n",
    "[1.02354094] [1.96896411]\n",
    "\n",
    "Более того, на основании нашей случайной выборки какие-то более точные значения коэффициентов получить уже практически нельзя.\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnxBhwkHp_z8"
   },
   "source": [
    "##**Тензоры**\n",
    "\n",
    "В пакетах машинного обучения основная работа ведётся как правило с тензорами.\n",
    "\n",
    "**Тензор** -- это обычно вектор (одномерный массив), двумерный массив (матрица), в общем случае многомерный массив.\n",
    "\n",
    "Операции над тензорами очень эффективно выполняются графическими процессорами, поэтому библиотеки машинного обучения оптимизируются под GPU.\n",
    "\n",
    "Над тензорами возможны как обычные арифметические матричные операции, так и множество дополнительных действий.\n",
    "\n",
    "**Скаляр** -- это массив с нулём измерений, или просто одно число.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fPMCGh3qVe-k"
   },
   "source": [
    "Введение и практика с тензорами на PyTorch, рекомендую пройти:\n",
    "\n",
    "https://github.com/DLSchool/dlschool/blob/master/06.%20PyTorch/%5Bseminar%5Dpytorch_basics.ipynb\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Hv1alqxqhmE"
   },
   "source": [
    "##**Берёмся за PyTorch**\n",
    "\n",
    "В PyTorch активно применяется понятие девайса.\n",
    "\n",
    "**Девайс (device)** -- устройство, на котором обрабатываются тензоры (графический процессор или обычный).\n",
    "\n",
    "Начало работы с PyTorch обычно строится по типовому шаблону:\n",
    "\n",
    "-- проверяем, доступны ли ресурсы GPU;\n",
    "\n",
    "-- готовим наши данные, преобразовывая в формат тензоров (для массивов NumPy это функция from_numpy);\n",
    "\n",
    "-- при желании данные можно привести к типу меньшей точности (например, 32-разрядному float), чтобы сэкономить ресурсы;\n",
    "\n",
    "-- выгружаем данные на конкретный девайс (GPU или обычный процессор) с помощью функции to().\n",
    "\n",
    "Тип тензора можно получить методом type(), который вернёт, например, torch.FloatTensor, если используется обычный процессор, или torch.cuda.FloatTensor, если GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "G6aeaa5fZqpK",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "import torch # подключаем основной пакет PyTorch\n",
    "\n",
    "# стандартная команда настройки девайса на GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# Наши исходные данные хранятся в формате массивов NumPy,\n",
    "# требуется преобразовать их в формат тензоров PyTorch,\n",
    "# привести к типу float и выгрузить на девайс\n",
    "x_train_tensor = torch.from_numpy(x_train).float().to(device)\n",
    "y_train_tensor = torch.from_numpy(y_train).float().to(device)\n",
    "print(x_train_tensor.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ns0XT4uYrQ6g"
   },
   "source": [
    "Теперь запрограммируем градиентный спуск, те же четыре шага, с помощью PyTorch.\n",
    "\n",
    "Сперва проинициализируем параметры (тензоры) a и b, используя случайные функции PyTorch.\n",
    "\n",
    "В параметрах функции генерации случайного значения torch.randn() в дополнение к понятным параметрам dtype (желаемый тип результирующего тензора) и целевой девайс (device), указывается очень важный requires_grad = True. Его смысл подробнее рассмотрим позже, но основная его идея в том, что он задаёт автоматическое вычисление градиента для данного тензора. Мы ведь считаем градиенты именно по этим двум параметрам a и b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YwVawk-PHnVW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# инициализация повторяемой посл-ти случайных чисел\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# задаём начальные случайные значения коэффициентам линейной регрессии\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6At-XHNsAUE"
   },
   "source": [
    "Значения a и b зависят от версии PyTorch.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fMgF9nksRl8"
   },
   "source": [
    "##**Autograd: автоматизируем расчёт градиентов**\n",
    "\n",
    "Autograd -- пакет автоматического дифференцирования PyTorch (один из трёх ключевых). Он очень крутой: можно забыть про частные производные, ручное программирование формул производных и многую другую математику -- теперь она скрыта под капотом autograd!\n",
    "\n",
    "https://pytorch.org/docs/stable/autograd.html?highlight=autograd#module-torch.autograd\n",
    "\n",
    "Нам теперь не нужно вручную программировать производные -- **вычисления всех градиентов выполняет универсальный метод backward()**. Так как мы вычисляем частные производные для лосса, к нему этот метод и применяем, вся магия совершится автоматически внутри него. А текущие значения градиентов мы можем получить обращением к атрибуту **grad** соответствующего тензора.\n",
    "\n",
    "Однако если далее мы захотим обновить параметры по старой схеме, появятся ошибки.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fRNMuJ4dgV-I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# скорость обучения\n",
    "lr = 0.1\n",
    "\n",
    "# количество эпох\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    # как и в примере с numpy, записываем нашу линейную зависимость,\n",
    "    # только теперь в качестве обучающей выборки -- тензор\n",
    "    yhat = a + b * x_train_tensor\n",
    "\n",
    "    # 1. считаем лосс как и раньше\n",
    "    error = y_train_tensor - yhat\n",
    "    loss = (error ** 2).mean()\n",
    "\n",
    "    # 2. вычисляем градиенты автоматически!\n",
    "    loss.backward()\n",
    "\n",
    "\n",
    "    # ПЕРВАЯ ПОПЫТКА (неверно)\n",
    "    # TypeError: unsupported operand type(s) for *: 'float' and 'NoneType'\n",
    "    # a = a - lr * a.grad\n",
    "    # b = b - lr * b.grad\n",
    "\n",
    "    # ВТОРАЯ ПОПЫТКА (неверно)\n",
    "    # RuntimeError: a leaf Variable that requires grad has been used in an in-place operation.\n",
    "    # a -= lr * a.grad\n",
    "    # b -= lr * b.grad\n",
    "\n",
    "    # ТРЕТЬЯ ПОПЫТКА (верно)\n",
    "    with torch.no_grad():\n",
    "        a -= lr * a.grad\n",
    "        b -= lr * b.grad\n",
    "\n",
    "    # Обнуляем градиенты вручную\n",
    "    a.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRz0O8-bBuYs"
   },
   "source": [
    "В первом случае мы не учли, что по умолчанию **все действия и операции над тензорами иммутабельны**. Мы формируем новые тензоры в процессе арифметических операций и при переназначении нашим параметрам их же обновлённых значений градиенты сбрасываются в начальное значение None, и возникает подобная ошибка.\n",
    "\n",
    "Нам надо выполнять обновления параметров непосредственно в них самих (**in place**) -- работать с ними как с мутабельными объектами, без создания промежуточных данных. Но и вторая попытка обновления с помощью стандартной питоновской in-place операции -= тоже выдаст ошибку.\n",
    "\n",
    "\n",
    "Дело в том, что PyTorch строит **динамический вычислительный граф** (см. далее) для каждой питоновской операции, которая прямо или косвенно связана с тензорами, для которых считаются градиенты. И чтобы временно отключить такой режим по умолчанию, надо воспользоваться методом **torch.no_grad()**, который позволяет выполнять операции над тензорами в отрыве от графа вычислений. Именно это мы и делаем в третьей попытке.\n",
    "\n",
    "\n",
    "И наконец, надо ещё учесть, что **градиенты автоматически не обнуляются, а накапливаются** -- в каждой эпохе их надо обнулять вручную. В PyTorch принято, что все методы по умолчанию иммутабельны (не воздействуют на своего родителя), а их мутабельные (in place) версии (полезные например, когда мы не хотим создавать промежуточные копии крупных объектов) отличаются символом подчёркивания в конце своего названия.\n",
    "Обнуление градиента \"на месте\" выполнит соответствующий метод **zero_()**.\n",
    "\n",
    "Итак, мы получаем итоговый результат, очень близкий к версии NumPy:\n",
    "tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Y67gyH5Du1A"
   },
   "source": [
    "##**Динамический граф вычислений**\n",
    "\n",
    "**Вычислительный граф** -- это направленный граф, в узлах которого выполняются некоторые вычисления.\n",
    "\n",
    "Вычисления в узлах графа используют данные, которые были вычислены в \"предыдущих\" узлах.\n",
    "\n",
    "Каждый узел графа -- по сути чистая функция, получающая на вход данные от связанных с ним узлов; по этой причине исполнение вычислительного графа хорошо распараллеливается.\n",
    "\n",
    "По большому счёту, от фреймворков машинного обучения требуются три основные вещи: **формировать граф вычислений, дифференцировать его, и вычислять**.\n",
    "В PyTorch такой граф строится динамически при запуске кода, и по нему можно проходить как вперёд, от начала к концу, так и обратно, от конца в начало.\n",
    "\n",
    "Зачем же этот граф нужен, как он связан с нашим кодом, как это вообще работает?\n",
    "\n",
    "Пакет PyTorchViz содержит средства визуализации графов вычислений. Установите его:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SAckCUd1j2j6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchviz in ./.venv/lib/python3.12/site-packages (0.0.2)\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.12/site-packages (from torchviz) (2.4.0)\n",
      "Requirement already satisfied: graphviz in ./.venv/lib/python3.12/site-packages (from torchviz) (0.20.3)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch->torchviz) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.12/site-packages (from torch->torchviz) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.12/site-packages (from torch->torchviz) (1.13.1)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch->torchviz) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch->torchviz) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch->torchviz) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch->torchviz) (72.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.venv/lib/python3.12/site-packages (from torch->torchviz) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.venv/lib/python3.12/site-packages (from torch->torchviz) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.venv/lib/python3.12/site-packages (from torch->torchviz) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.venv/lib/python3.12/site-packages (from torch->torchviz) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.venv/lib/python3.12/site-packages (from torch->torchviz) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.venv/lib/python3.12/site-packages (from torch->torchviz) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.venv/lib/python3.12/site-packages (from torch->torchviz) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.venv/lib/python3.12/site-packages (from torch->torchviz) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.venv/lib/python3.12/site-packages (from torch->torchviz) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./.venv/lib/python3.12/site-packages (from torch->torchviz) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.venv/lib/python3.12/site-packages (from torch->torchviz) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in ./.venv/lib/python3.12/site-packages (from torch->torchviz) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.venv/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->torchviz) (12.6.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch->torchviz) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy->torch->torchviz) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8t6nPBcEI4u"
   },
   "source": [
    "Подготовим минималистичный код: два тензора с поддержкой градиентов, формулу прогнозирования, погрешость и лосс.\n",
    "\n",
    "Функция **make_dot(yhat)**, получающая на вход тензор, связанный с формулой прогнозирования, сформирует такое изображение графа:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "UXJlTuHZiewG"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"222pt\" height=\"448pt\"\n",
       " viewBox=\"0.00 0.00 222.00 448.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 444)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-444 218,-444 218,4 -4,4\"/>\n",
       "<!-- 140458156769680 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140458156769680</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"133.5,-31 79.5,-31 79.5,0 133.5,0 133.5,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"106.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
       "</g>\n",
       "<!-- 140458160877920 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140458160877920</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"154,-86 59,-86 59,-67 154,-67 154,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"106.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">MeanBackward0</text>\n",
       "</g>\n",
       "<!-- 140458160877920&#45;&gt;140458156769680 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>140458160877920&#45;&gt;140458156769680</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M106.5,-66.79C106.5,-60.07 106.5,-50.4 106.5,-41.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"110,-41.19 106.5,-31.19 103,-41.19 110,-41.19\"/>\n",
       "</g>\n",
       "<!-- 140455181908048 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140455181908048</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"151,-141 62,-141 62,-122 151,-122 151,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"106.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n",
       "</g>\n",
       "<!-- 140455181908048&#45;&gt;140458160877920 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140455181908048&#45;&gt;140458160877920</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M106.5,-121.75C106.5,-114.8 106.5,-104.85 106.5,-96.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"110,-96.09 106.5,-86.09 103,-96.09 110,-96.09\"/>\n",
       "</g>\n",
       "<!-- 140458540282112 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140458540282112</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"151,-196 62,-196 62,-177 151,-177 151,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"106.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\n",
       "</g>\n",
       "<!-- 140458540282112&#45;&gt;140455181908048 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140458540282112&#45;&gt;140455181908048</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M106.5,-176.75C106.5,-169.8 106.5,-159.85 106.5,-151.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"110,-151.09 106.5,-141.09 103,-151.09 110,-151.09\"/>\n",
       "</g>\n",
       "<!-- 140458540281968 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140458540281968</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"151,-251 62,-251 62,-232 151,-232 151,-251\"/>\n",
       "<text text-anchor=\"middle\" x=\"106.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 140458540281968&#45;&gt;140458540282112 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140458540281968&#45;&gt;140458540282112</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M106.5,-231.75C106.5,-224.8 106.5,-214.85 106.5,-206.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"110,-206.09 106.5,-196.09 103,-206.09 110,-206.09\"/>\n",
       "</g>\n",
       "<!-- 140458540282448 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>140458540282448</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-306 0,-306 0,-287 101,-287 101,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140458540282448&#45;&gt;140458540281968 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140458540282448&#45;&gt;140458540281968</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M59.5,-286.98C67.69,-279.23 80.01,-267.58 89.97,-258.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"92.48,-260.59 97.34,-251.17 87.67,-255.5 92.48,-260.59\"/>\n",
       "</g>\n",
       "<!-- 140455177980256 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>140455177980256</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-373 23.5,-373 23.5,-342 77.5,-342 77.5,-373\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 140455177980256&#45;&gt;140458540282448 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140455177980256&#45;&gt;140458540282448</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-341.92C50.5,-334.22 50.5,-324.69 50.5,-316.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-316.25 50.5,-306.25 47,-316.25 54,-316.25\"/>\n",
       "</g>\n",
       "<!-- 140458540282208 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>140458540282208</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"208,-306 119,-306 119,-287 208,-287 208,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"163.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n",
       "</g>\n",
       "<!-- 140458540282208&#45;&gt;140458540281968 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>140458540282208&#45;&gt;140458540281968</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M154.34,-286.98C146,-279.23 133.47,-267.58 123.32,-258.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"125.53,-255.42 115.82,-251.17 120.76,-260.54 125.53,-255.42\"/>\n",
       "</g>\n",
       "<!-- 140458540282400 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>140458540282400</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"214,-367 113,-367 113,-348 214,-348 214,-367\"/>\n",
       "<text text-anchor=\"middle\" x=\"163.5\" y=\"-355\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140458540282400&#45;&gt;140458540282208 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>140458540282400&#45;&gt;140458540282208</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M163.5,-347.79C163.5,-339.6 163.5,-327.06 163.5,-316.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"167,-316.24 163.5,-306.24 160,-316.24 167,-316.24\"/>\n",
       "</g>\n",
       "<!-- 140456791719792 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>140456791719792</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"190.5,-440 136.5,-440 136.5,-409 190.5,-409 190.5,-440\"/>\n",
       "<text text-anchor=\"middle\" x=\"163.5\" y=\"-416\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 140456791719792&#45;&gt;140458540282400 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>140456791719792&#45;&gt;140458540282400</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M163.5,-408.75C163.5,-399.39 163.5,-387.19 163.5,-377.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"167,-377.02 163.5,-367.02 160,-377.02 167,-377.02\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fbf0d6630e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchviz\n",
    "\n",
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "\n",
    "yhat = a + b * x_train_tensor\n",
    "error = y_train_tensor - yhat\n",
    "loss = (error ** 2).mean()\n",
    "\n",
    "torchviz.make_dot(loss) # визуализируем граф вычислений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzxnH0iEEUAM"
   },
   "source": [
    "Синие квадратики -- это наши параметры, тензоры, для которых считаются градиенты. Серые квадратики -- это операции Python над этими тензорами или над зависимыми от них значениями.\n",
    "\n",
    "Зелёные квадратики -- то же, что и серые, только в них вычисляются градиенты.\n",
    "\n",
    "Кто знаком с абстрактным синтаксическим деревом, наверняка увидит тут определённое сходство.\n",
    "\n",
    "По названиям квадратов легко определить их смысл -- префиксы определяют вид арифметических операций. Сперва Mul (умножение) выполняет умножение одного параметра: b * x_train_tensor, затем результат складывается (Add) с вторым параметром a, далее из y_train_tensor вычитается (Sub) что получилось, затем возводится в степень (Pow), и наконец вычисление среднего Mean -- это заключительная точка, в которой будут рассчитываться градиенты.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "**Вычисление градиентов в графе происходит снизу вверх!** Зелёный квадрат -- это стартовая точка такого процесса. Не вдаваясь в детали, отметим, что это так называемое **обратное автоматическое дифференцирование** -- мы начинаем с операции, где было получено результирующее значение, и движемся от неё обратно по графу, вычисляя таким образом производные.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FU8kqbrEE0ek"
   },
   "source": [
    "Почему в одних случаях в квадраты входят две стрелки (как и должно быть с точки зрения двух параметров арифметических операций), а в других всего одна? Какой там второй параметр арифметической операции?\n",
    "\n",
    "Дело в том, что в графе не требуются отдельные квадраты для, например, x или y, потому что мы не считаем градиенты для них. Независимо от количества задействованных тензоров в выражении **в графе учитываются только те параметры, для которых вычисляются градиенты**.\n",
    "\n",
    "Например, попробуйте изменить в команде создания параметра \"a\" его настройку requires_grad на False:\n",
    "\n",
    "`a = torch.randn(1, requires_grad=False, dtype=torch.float, device=device)`\n",
    "\n",
    "Получится граф из шести квадратиков, которые будут линейно связаны друг с другом одиночными стрелками.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcUP191pFnNO"
   },
   "source": [
    "##**Задание 1**\n",
    "\n",
    "Выведите графы для error и yhat -- почему получились такие отличия?\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"222pt\" height=\"338pt\"\n",
       " viewBox=\"0.00 0.00 222.00 338.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 334)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-334 218,-334 218,4 -4,4\"/>\n",
       "<!-- 140458540431744 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140458540431744</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"139,-31 74,-31 74,0 139,0 139,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"106.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (80, 1)</text>\n",
       "</g>\n",
       "<!-- 140455178115952 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140455178115952</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"151,-86 62,-86 62,-67 151,-67 151,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"106.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\n",
       "</g>\n",
       "<!-- 140455178115952&#45;&gt;140458540431744 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>140455178115952&#45;&gt;140458540431744</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M106.5,-66.79C106.5,-60.07 106.5,-50.4 106.5,-41.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"110,-41.19 106.5,-31.19 103,-41.19 110,-41.19\"/>\n",
       "</g>\n",
       "<!-- 140455178114368 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140455178114368</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"151,-141 62,-141 62,-122 151,-122 151,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"106.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 140455178114368&#45;&gt;140455178115952 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140455178114368&#45;&gt;140455178115952</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M106.5,-121.75C106.5,-114.8 106.5,-104.85 106.5,-96.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"110,-96.09 106.5,-86.09 103,-96.09 110,-96.09\"/>\n",
       "</g>\n",
       "<!-- 140455176539728 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140455176539728</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-196 0,-196 0,-177 101,-177 101,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140455176539728&#45;&gt;140455178114368 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140455176539728&#45;&gt;140455178114368</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M59.5,-176.98C67.69,-169.23 80.01,-157.58 89.97,-148.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"92.48,-150.59 97.34,-141.17 87.67,-145.5 92.48,-150.59\"/>\n",
       "</g>\n",
       "<!-- 140458540429904 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140458540429904</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-263 23.5,-263 23.5,-232 77.5,-232 77.5,-263\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 140458540429904&#45;&gt;140455176539728 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140458540429904&#45;&gt;140455176539728</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-231.92C50.5,-224.22 50.5,-214.69 50.5,-206.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-206.25 50.5,-196.25 47,-206.25 54,-206.25\"/>\n",
       "</g>\n",
       "<!-- 140455176551536 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>140455176551536</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"208,-196 119,-196 119,-177 208,-177 208,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"163.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n",
       "</g>\n",
       "<!-- 140455176551536&#45;&gt;140455178114368 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140455176551536&#45;&gt;140455178114368</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M154.34,-176.98C146,-169.23 133.47,-157.58 123.32,-148.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"125.53,-145.42 115.82,-141.17 120.76,-150.54 125.53,-145.42\"/>\n",
       "</g>\n",
       "<!-- 140455184174864 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>140455184174864</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"214,-257 113,-257 113,-238 214,-238 214,-257\"/>\n",
       "<text text-anchor=\"middle\" x=\"163.5\" y=\"-245\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140455184174864&#45;&gt;140455176551536 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140455184174864&#45;&gt;140455176551536</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M163.5,-237.79C163.5,-229.6 163.5,-217.06 163.5,-206.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"167,-206.24 163.5,-196.24 160,-206.24 167,-206.24\"/>\n",
       "</g>\n",
       "<!-- 140458540426784 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>140458540426784</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"190.5,-330 136.5,-330 136.5,-299 190.5,-299 190.5,-330\"/>\n",
       "<text text-anchor=\"middle\" x=\"163.5\" y=\"-306\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 140458540426784&#45;&gt;140455184174864 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>140458540426784&#45;&gt;140455184174864</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M163.5,-298.75C163.5,-289.39 163.5,-277.19 163.5,-267.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"167,-267.02 163.5,-257.02 160,-267.02 167,-267.02\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fbe44ff9a60>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchviz\n",
    "\n",
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "\n",
    "yhat = a + b * x_train_tensor\n",
    "error = y_train_tensor - yhat\n",
    "loss = (error ** 2).mean()\n",
    "\n",
    "torchviz.make_dot(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"222pt\" height=\"283pt\"\n",
       " viewBox=\"0.00 0.00 222.00 283.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 279)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-279 218,-279 218,4 -4,4\"/>\n",
       "<!-- 140458540430064 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140458540430064</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"139,-31 74,-31 74,0 139,0 139,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"106.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (80, 1)</text>\n",
       "</g>\n",
       "<!-- 140455178114368 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140455178114368</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"151,-86 62,-86 62,-67 151,-67 151,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"106.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 140455178114368&#45;&gt;140458540430064 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>140455178114368&#45;&gt;140458540430064</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M106.5,-66.79C106.5,-60.07 106.5,-50.4 106.5,-41.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"110,-41.19 106.5,-31.19 103,-41.19 110,-41.19\"/>\n",
       "</g>\n",
       "<!-- 140455176539728 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140455176539728</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-141 0,-141 0,-122 101,-122 101,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140455176539728&#45;&gt;140455178114368 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140455176539728&#45;&gt;140455178114368</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M59.5,-121.98C67.69,-114.23 80.01,-102.58 89.97,-93.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"92.48,-95.59 97.34,-86.17 87.67,-90.5 92.48,-95.59\"/>\n",
       "</g>\n",
       "<!-- 140458540429904 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140458540429904</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-208 23.5,-208 23.5,-177 77.5,-177 77.5,-208\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 140458540429904&#45;&gt;140455176539728 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140458540429904&#45;&gt;140455176539728</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-176.92C50.5,-169.22 50.5,-159.69 50.5,-151.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-151.25 50.5,-141.25 47,-151.25 54,-151.25\"/>\n",
       "</g>\n",
       "<!-- 140455176551536 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140455176551536</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"208,-141 119,-141 119,-122 208,-122 208,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"163.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n",
       "</g>\n",
       "<!-- 140455176551536&#45;&gt;140455178114368 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140455176551536&#45;&gt;140455178114368</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M154.34,-121.98C146,-114.23 133.47,-102.58 123.32,-93.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"125.53,-90.42 115.82,-86.17 120.76,-95.54 125.53,-90.42\"/>\n",
       "</g>\n",
       "<!-- 140455184174864 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>140455184174864</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"214,-202 113,-202 113,-183 214,-183 214,-202\"/>\n",
       "<text text-anchor=\"middle\" x=\"163.5\" y=\"-190\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140455184174864&#45;&gt;140455176551536 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140455184174864&#45;&gt;140455176551536</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M163.5,-182.79C163.5,-174.6 163.5,-162.06 163.5,-151.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"167,-151.24 163.5,-141.24 160,-151.24 167,-151.24\"/>\n",
       "</g>\n",
       "<!-- 140458540426784 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>140458540426784</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"190.5,-275 136.5,-275 136.5,-244 190.5,-244 190.5,-275\"/>\n",
       "<text text-anchor=\"middle\" x=\"163.5\" y=\"-251\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 140458540426784&#45;&gt;140455184174864 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140458540426784&#45;&gt;140455184174864</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M163.5,-243.75C163.5,-234.39 163.5,-222.19 163.5,-212.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"167,-212.02 163.5,-202.02 160,-212.02 167,-212.02\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fbf0d690d10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchviz.make_dot(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4o_iqiMF7NY"
   },
   "source": [
    "##**Дифференцирование условных конструкций**\n",
    "\n",
    "Самая крутая особенность динамического вычислительного графа в PyTorch в том, что он понимает фактически любые управляющие конструкции Python, код любой сложности. Это по сути означает, что их тоже можно дифференцировать!\n",
    "\n",
    "Следующий код, дополненный условием (оно само по себе не имеет никакого смысла), выведет интересный граф:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "d8Ne289G42UQ"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"326pt\" height=\"503pt\"\n",
       " viewBox=\"0.00 0.00 326.00 503.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 499)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-499 322,-499 322,4 -4,4\"/>\n",
       "<!-- 140458540424224 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140458540424224</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"242.5,-31 188.5,-31 188.5,0 242.5,0 242.5,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"215.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
       "</g>\n",
       "<!-- 140455185451760 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140455185451760</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"260,-86 171,-86 171,-67 260,-67 260,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"215.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 140455185451760&#45;&gt;140458540424224 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>140455185451760&#45;&gt;140458540424224</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M215.5,-66.79C215.5,-60.07 215.5,-50.4 215.5,-41.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"219,-41.19 215.5,-31.19 212,-41.19 219,-41.19\"/>\n",
       "</g>\n",
       "<!-- 140459189155680 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140459189155680</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"225,-141 130,-141 130,-122 225,-122 225,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"177.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">MeanBackward0</text>\n",
       "</g>\n",
       "<!-- 140459189155680&#45;&gt;140455185451760 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140459189155680&#45;&gt;140455185451760</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M183.77,-121.75C189.09,-114.34 196.86,-103.5 203.38,-94.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206.36,-96.26 209.34,-86.09 200.67,-92.18 206.36,-96.26\"/>\n",
       "</g>\n",
       "<!-- 140458540111168 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140458540111168</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"205,-196 116,-196 116,-177 205,-177 205,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"160.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n",
       "</g>\n",
       "<!-- 140458540111168&#45;&gt;140459189155680 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140458540111168&#45;&gt;140459189155680</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M163.31,-176.75C165.56,-169.72 168.8,-159.62 171.62,-150.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"175.02,-151.68 174.75,-141.09 168.36,-149.54 175.02,-151.68\"/>\n",
       "</g>\n",
       "<!-- 140455177821424 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140455177821424</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"205,-251 116,-251 116,-232 205,-232 205,-251\"/>\n",
       "<text text-anchor=\"middle\" x=\"160.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\n",
       "</g>\n",
       "<!-- 140455177821424&#45;&gt;140458540111168 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140455177821424&#45;&gt;140458540111168</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M160.5,-231.75C160.5,-224.8 160.5,-214.85 160.5,-206.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"164,-206.09 160.5,-196.09 157,-206.09 164,-206.09\"/>\n",
       "</g>\n",
       "<!-- 140458540283168 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>140458540283168</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"205,-306 116,-306 116,-287 205,-287 205,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"160.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 140458540283168&#45;&gt;140455177821424 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140458540283168&#45;&gt;140455177821424</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M160.5,-286.75C160.5,-279.8 160.5,-269.85 160.5,-261.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"164,-261.09 160.5,-251.09 157,-261.09 164,-261.09\"/>\n",
       "</g>\n",
       "<!-- 140458540283072 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>140458540283072</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-361 0,-361 0,-342 101,-342 101,-361\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140458540283072&#45;&gt;140458540283168 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140458540283072&#45;&gt;140458540283168</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M68.17,-341.98C85.79,-333.5 113.08,-320.35 133.43,-310.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"135.02,-313.66 142.51,-306.17 131.98,-307.36 135.02,-313.66\"/>\n",
       "</g>\n",
       "<!-- 140455177979856 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>140455177979856</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-428 23.5,-428 23.5,-397 77.5,-397 77.5,-428\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-404\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 140455177979856&#45;&gt;140458540283072 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>140455177979856&#45;&gt;140458540283072</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-396.92C50.5,-389.22 50.5,-379.69 50.5,-371.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-371.25 50.5,-361.25 47,-371.25 54,-371.25\"/>\n",
       "</g>\n",
       "<!-- 140458540283600 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>140458540283600</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"208,-361 119,-361 119,-342 208,-342 208,-361\"/>\n",
       "<text text-anchor=\"middle\" x=\"163.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n",
       "</g>\n",
       "<!-- 140458540283600&#45;&gt;140458540283168 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>140458540283600&#45;&gt;140458540283168</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M163,-341.75C162.61,-334.8 162.05,-324.85 161.55,-316.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"165.05,-315.88 160.99,-306.09 158.06,-316.27 165.05,-315.88\"/>\n",
       "</g>\n",
       "<!-- 140458540271312 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>140458540271312</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"267,-422 166,-422 166,-403 267,-403 267,-422\"/>\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-410\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140458540271312&#45;&gt;140458540283600 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>140458540271312&#45;&gt;140458540283600</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M208.68,-402.79C200.69,-393.91 188.11,-379.89 178.24,-368.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"180.64,-366.34 171.35,-361.24 175.43,-371.02 180.64,-366.34\"/>\n",
       "</g>\n",
       "<!-- 140458540283648 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>140458540283648</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"315,-361 226,-361 226,-342 315,-342 315,-361\"/>\n",
       "<text text-anchor=\"middle\" x=\"270.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n",
       "</g>\n",
       "<!-- 140458540271312&#45;&gt;140458540283648 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>140458540271312&#45;&gt;140458540283648</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M224.47,-402.79C232.6,-393.91 245.43,-379.89 255.48,-368.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"258.33,-370.98 262.5,-361.24 253.17,-366.26 258.33,-370.98\"/>\n",
       "</g>\n",
       "<!-- 140458540424144 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>140458540424144</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"243.5,-495 189.5,-495 189.5,-464 243.5,-464 243.5,-495\"/>\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-471\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 140458540424144&#45;&gt;140458540271312 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>140458540424144&#45;&gt;140458540271312</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M216.5,-463.75C216.5,-454.39 216.5,-442.19 216.5,-432.16\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"220,-432.02 216.5,-422.02 213,-432.02 220,-432.02\"/>\n",
       "</g>\n",
       "<!-- 140459189157120 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>140459189157120</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"318,-196 223,-196 223,-177 318,-177 318,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"270.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">MeanBackward0</text>\n",
       "</g>\n",
       "<!-- 140459189157120&#45;&gt;140455185451760 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>140459189157120&#45;&gt;140455185451760</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M266,-176.66C256.97,-158.93 236.5,-118.73 224.57,-95.32\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"227.57,-93.48 219.91,-86.16 221.33,-96.66 227.57,-93.48\"/>\n",
       "</g>\n",
       "<!-- 140455177820992 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>140455177820992</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"315,-306 226,-306 226,-287 315,-287 315,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"270.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\n",
       "</g>\n",
       "<!-- 140455177820992&#45;&gt;140459189157120 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>140455177820992&#45;&gt;140459189157120</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M270.5,-286.66C270.5,-269.17 270.5,-229.8 270.5,-206.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"274,-206.16 270.5,-196.16 267,-206.16 274,-206.16\"/>\n",
       "</g>\n",
       "<!-- 140458540283648&#45;&gt;140455177820992 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>140458540283648&#45;&gt;140455177820992</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M270.5,-341.75C270.5,-334.8 270.5,-324.85 270.5,-316.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"274,-316.09 270.5,-306.09 267,-316.09 274,-316.09\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fbf34133500>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchviz\n",
    "\n",
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "\n",
    "yhat = a + b * x_train_tensor\n",
    "error = y_train_tensor - yhat\n",
    "loss = (error ** 2).mean()\n",
    "\n",
    "# это полная чушь! этот код только для демонстрации разветвления в графе!\n",
    "if loss > 0:\n",
    "  yhat2 = b * x_train_tensor\n",
    "  error2 = y_train_tensor - yhat2\n",
    "\n",
    "loss += error2.mean()\n",
    "\n",
    "torchviz.make_dot(loss) # визуализируем граф вычислений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SV4DeKF9GB3A"
   },
   "source": [
    "**Важно**. В графе формируется не линейная последовательность действий, как в коде.\n",
    "\n",
    "**Граф -- это не блок-схема!** В случае блок-схемы алгоритма требовалось бы делать разветвление после первого расчёта loss, а в данном случае видны два независимых вычислительных блока, которые разветвляются не по условию if loss > 0 , а по вхождению параметров (в данном случае параметра b) в различные цепочки вычислений. Эти блоки/цепочки в процессе вычисления градиентов комбинируются автоматически.\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fR3Zp9aHz5m"
   },
   "source": [
    "##**Оптимизатор**\n",
    "\n",
    "Несмотря на автоматическое вычисление градиентов, сейчас мы, как и в случае с NumPy, параметры обновляем вручную, явными командами в коде. Сейчас их всего два, но что если их будут сотни или тысячи, как в крупных и сложных моделях? На помощь приходят оптимизаторы. **Пакет torch.optim -- это второй из трёх ключевых пакетов PyTorch**.\n",
    "\n",
    "\n",
    "\n",
    "Оптимизатор получает на вход список параметров, скорость обучения и возможно ещё ряд других настроечных коэффициентов, и выполняет их автоматическое обновление с помощью метода **step().** Не требуется в таком случае и ручного обнуления градиентов -- для этого есть метод **zero_grad()**.\n",
    "\n",
    "\n",
    "Различные алгоритмы оптимизации и реализованы в данном пакете torch.optim.  Один из популярных алгоритмов -- это **стохастический градиентный спуск** (Stochastic Gradient Descent, SGD). Как он работает внутри, на данном шаге неважно, достаточно знать, что он умеет реализовывать пакетный спуск -- используя в обновлении сразу всю обучающую выборку.\n",
    "\n",
    "https://pytorch.org/docs/stable/optim.html?source=post_page---------------------------#torch.optim.SGD\n",
    "\n",
    "Всё, что потребуется изменить в исходном коде -- это создать сам оптимизатор, связав его с параметрами, и соответственно, сменить ручное обновление параметров a и b и обнуление их градиентов на вызов методов оптимизатора step() и zero_grad().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "mohMh0ECmw1K",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n",
      "tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "print(a, b)\n",
    "\n",
    "# скорость обучения\n",
    "lr = 0.1\n",
    "\n",
    "# количество эпох\n",
    "n_epochs = 1000\n",
    "\n",
    "# создаём SGD оптимизатор для автоматического обновления параметров\n",
    "optimizer = optim.SGD([a, b], lr=lr)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    yhat = a + b * x_train_tensor\n",
    "    error = y_train_tensor - yhat\n",
    "    loss = (error ** 2).mean()\n",
    "    loss.backward()\n",
    "\n",
    "    # with torch.no_grad():\n",
    "    #    a -= lr * a.grad\n",
    "    #    b -= lr * b.grad\n",
    "    optimizer.step()\n",
    "\n",
    "    # a.grad.zero_()\n",
    "    # b.grad.zero_()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7RIFwl0ISpm"
   },
   "source": [
    "Параметры в начале и после обучения:\n",
    "\n",
    "tensor([0.1940], device='cuda:0', requires_grad=True) tensor([0.1391], device='cuda:0', requires_grad=True)\n",
    "\n",
    "tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n",
    "\n",
    "По сути, мы таким образом оптимизировали процесс оптимизации!\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhSl1VXCIiQc"
   },
   "source": [
    "##**Лосс**\n",
    "\n",
    "Сейчас и лосс мы пока считаем вручную, явно записывая формулу расчёта\n",
    "loss = (error ** 2).mean(). На помощь приходит **третий (из трёх) ключевой пакет PyTorch -- torch.nn**, добавляющий уровень абстракции для довольно низкоуровневых возможностей autograd.\n",
    "\n",
    "https://pytorch.org/docs/stable/nn.html?highlight=nn#module-torch.nn\n",
    "\n",
    "В нём, в частности, содержится набор стандартных функций для расчёта всевозможных видов ошибок/погрешностей.\n",
    "\n",
    "В нашем случае, функция расчёта среднеквадратичной ошибки называется **MSELoss**. Сама по себе это не функция, которая вызывается напрямую, а скорее \"фабрика\" функций, которая создаёт нужную нам функцию, причём можно этой фабрике задавать параметры желаемой функций, методы агрегации данных (например, reduction=\"mean\" означает вычисление среднего, reduction=\"sum\" означает вычисление суммы). На вход подобным функциям подаётся обучающая выборка и тензор с параметрами, для которых рассчитываются градиенты.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "93krP0x3uCY8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n",
      "tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from torch import optim, nn\n",
    "\n",
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "print(a, b)\n",
    "\n",
    "# скорость обучения\n",
    "lr = 0.1\n",
    "\n",
    "# количество эпох\n",
    "n_epochs = 1000\n",
    "\n",
    "# функция расчёта лосса\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# создаём SGD оптимизатор для автоматического обновления параметров\n",
    "optimizer = optim.SGD([a, b], lr=lr)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    yhat = a + b * x_train_tensor\n",
    "\n",
    "    # error = y_train_tensor - yhat\n",
    "    # loss = (error ** 2).mean()\n",
    "    loss = loss_fn(yhat, y_train_tensor)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fT1znvwTI7lw"
   },
   "source": [
    "Обратите внимание, что мы уже избавились фактически от всего ручного кодирования, связанного с градиентами и другими оптимизационными расчётами!\n",
    "\n",
    "**Получился по сути шаблон, в котором осталась только явно одна задаваемая вручную строка, где вычисляется yhat -- она определяет нашу формулу прогноза, и её можно менять на любые другие нужные нам для анализа зависимости.**\n",
    "\n",
    "Соответственно, напрашивается вопрос, а можно ли как-то абстрагировать и этот момент, чтобы не искать в оптимизационном коде нужную строчку, да и в целом перейти на более удобный формат представления изучаемых зависимостей? Такая форма абстракции в PyTorch -- это модель.\n",
    "\n",
    "Созданию моделей PyTorch посвящено следующее занятие."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4W1syOJ0Oo9a"
   },
   "source": [
    "##**Задание 2**\n",
    "\n",
    "Измените в данном шаблоне прогноз на основе линейной регрессии на более сложную зависимость. С функциями прогноза какой сложности сможет уверенно справиться наш простой базовый шаблон PyTorch?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0d3WkxEVV1F-"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "https://vk.com/lambda_brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True) tensor([0.2345], requires_grad=True)\n",
      "tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "tensor([1.1243], requires_grad=True) tensor([1.3164], requires_grad=True) tensor([0.6555], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from torch import optim, nn\n",
    "\n",
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "c = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "print(a, b, c)\n",
    "\n",
    "# скорость обучения\n",
    "lr = 0.1\n",
    "\n",
    "# количество эпох\n",
    "n_epochs = 1000\n",
    "\n",
    "# функция расчёта лосса\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# создаём SGD оптимизатор для автоматического обновления параметров\n",
    "optimizer = optim.SGD([a, b, c], lr=lr)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # добавление квадратичного члена\n",
    "    yhat = a + b * x_train_tensor + c * x_train_tensor ** 2\n",
    "    loss = loss_fn(yhat, y_train_tensor)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "print(loss)\n",
    "print(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в идеале при дальнейшем обучении коээфициент при побочном (квадратичном) \n",
    "# члене c должен стремиться к нулю, а наши коэффициенты a и b должны стремиться к их реальным значениям \n",
    "# попробуем увеличить количество эпох"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True) tensor([0.2345], requires_grad=True)\n",
      "tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "tensor([1.0598], requires_grad=True) tensor([1.7265], requires_grad=True) tensor([0.2471], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from torch import optim, nn\n",
    "\n",
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "c = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "print(a, b, c)\n",
    "\n",
    "# скорость обучения\n",
    "lr = 0.1\n",
    "\n",
    "# количество эпох\n",
    "n_epochs = 5000\n",
    "\n",
    "# функция расчёта лосса\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# создаём SGD оптимизатор для автоматического обновления параметров\n",
    "optimizer = optim.SGD([a, b, c], lr=lr)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # добавление квадратичного члена\n",
    "    yhat = a + b * x_train_tensor + c * x_train_tensor ** 2\n",
    "    loss = loss_fn(yhat, y_train_tensor)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "print(loss)\n",
    "print(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# видим, что коэффициент c все еще имеет значимый вклад в нашу функцию прогнозирования\n",
    "# попробуем это исправить путем увеличения скорости обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True) tensor([0.2345], requires_grad=True)\n",
      "tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "tensor([1.0513], requires_grad=True) tensor([1.7807], requires_grad=True) tensor([0.1931], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from torch import optim, nn\n",
    "\n",
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "c = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "print(a, b, c)\n",
    "\n",
    "# скорость обучения\n",
    "lr = 0.2\n",
    "\n",
    "# количество эпох\n",
    "n_epochs = 5000\n",
    "\n",
    "# функция расчёта лосса\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# создаём SGD оптимизатор для автоматического обновления параметров\n",
    "optimizer = optim.SGD([a, b, c], lr=lr)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # добавление квадратичного члена\n",
    "    yhat = a + b * x_train_tensor + c * x_train_tensor ** 2\n",
    "    loss = loss_fn(yhat, y_train_tensor)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "print(loss)\n",
    "print(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# видим, что даже при увелечении в два раза шага обучения (скорости обучения), \n",
    "# мы все еще имеем немалый вклад квадратичного члена\n",
    "# можно предположить, что при дальнейшем обучении, более приближенных к реальным значений коэффициентов мы не получим,\n",
    "# как и не получим меньшее значение ошибки поскольку мы не имеем достаточного количества тренировочных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True) tensor([0.2345], requires_grad=True)\n",
      "tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "tensor([1.0506], requires_grad=True) tensor([1.7850], requires_grad=True) tensor([0.1888], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from torch import optim, nn\n",
    "\n",
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "c = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "print(a, b, c)\n",
    "\n",
    "# скорость обучения\n",
    "lr = 0.2\n",
    "\n",
    "# количество эпох\n",
    "n_epochs = 10000\n",
    "\n",
    "# функция расчёта лосса\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# создаём SGD оптимизатор для автоматического обновления параметров\n",
    "optimizer = optim.SGD([a, b, c], lr=lr)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # добавление квадратичного члена\n",
    "    yhat = a + b * x_train_tensor + c * x_train_tensor ** 2\n",
    "    loss = loss_fn(yhat, y_train_tensor)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "print(loss)\n",
    "print(a, b, c)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
