{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ov4K97EJbu4"
   },
   "source": [
    "# **Занятие 6. Свёрточные нейронные сети. Классификация цветных изображений**\n",
    "\n",
    "https://vk.com/lambda_brain\n",
    "\n",
    "Рассмотрим случай, когда входные данные -- это цветные изображения. Для обработки таких данных были придуманы **свёрточные нейронные сети**, воспользуемся для этого одной из классических моделей.\n",
    "\n",
    "---\n",
    "\n",
    "Импортируем нужные пакеты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8abpHoRq6V-L"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "goNhmuPOJ-BV"
   },
   "source": [
    "Будем обрабатывать стандартный датасет **CIFAR10**, который включает фотографии десяти классов: самолёт, автомобиль, птица, кот, олень, собака, лягушка, лошадь, корабль и грузовик. На каждый класс приходится по 6000 (5000 обучающих и 1000 тестовых) цветных изображений размером 32 * 32 пиксела (и три канала цветности RGB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UfwVbruB8gQb"
   },
   "outputs": [],
   "source": [
    "input_size = 3*32*32   # Размер изображения в точках * количество цветов\n",
    "num_classes = 10       # Количество распознающихся классов (10 видов изображений)\n",
    "n_epochs = 2           # Количество эпох\n",
    "batch_size = 4         # Размер мини-пакета входных данных\n",
    "lr = 0.001             # Скорость обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPSaBAmrKJ5p"
   },
   "source": [
    "Из-за специфики представления цветных изображений мы не можем сразу брать их в сыром виде: сперва требуется нормализовать картинки, превратить их в изображения с интенсивностью цвета в диапазоне 0..1. Это делает стандартная функция **Normalize()** из torchvision.transforms, которой в качестве параметров в подобных случаях обычно указываются стандартные значения (среднее и стандартное отклонение) для такой нормализации (0.5, 0.5, 0.5).\n",
    "\n",
    "То есть нам нужно выполнить композицию трансформаций: сперва выполнить преобразование в тензоры, и затем нормализовать.\n",
    "\n",
    "Композицию выполняет стандартная функция torchvision.transforms **.Compose()**. Её результат мы и задаём в качестве параметра transform конструктора CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0eX2jdtCLzWd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "cifar_trainset = dsets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbncbyBiKid7"
   },
   "source": [
    "Аналогично подготовим и тестовый датасет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8jKhtNW7L7YI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "50000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "cifar_testset = dsets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "print(len(cifar_trainset))\n",
    "print(len(cifar_testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lug1CvTJKmHb"
   },
   "source": [
    "Загрузим наши данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "brvDSwBVNqqS"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=cifar_trainset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=cifar_testset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MeC-wQZ0KpJq"
   },
   "source": [
    "Добавим стандартный шаг обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TCBltxfGOChj"
   },
   "outputs": [],
   "source": [
    "# импортируем нужные библиотеки\n",
    "import torch\n",
    "import numpy as np # всегда пригодится :)\n",
    "from torch.nn import Linear, Sigmoid\n",
    "\n",
    "# инициализируем девайс\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# добавляем типовую функцию \"шаг обучения\"\n",
    "def make_train_step(model, loss_fn, optimizer):\n",
    "    def train_step(x, y):\n",
    "        model.train()\n",
    "        yhat = model(x)\n",
    "        loss = loss_fn(yhat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        return loss.item()\n",
    "    return train_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdK0PPStSWwH"
   },
   "source": [
    "Какую задействовать модель? Вообще, конструирование наиболее эффективных моделей -- это искусство плюс математика. На практике часто можно пользоваться либо простыми стандартными решениями (как было например в случае распознавания рукописных цифр), либо сложными моделями, которые под соответствующие классы задач придумали ведущие специалисты в ML.\n",
    "В нашем случае мы применим модель LeNet, предложенную Яном ЛеКуном -- она относится к так называемым **свёрточным нейронным сетям (Convolutional Neural Network, CNN)**, хорошо работающим с двумерными изображениями.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Подробное описание принципов работы CNN:\n",
    "\n",
    "https://neurohive.io/ru/tutorial/cnn-na-pytorch/\n",
    "\n",
    "Главное, обратите внимание на принцип **свёртки** и движущееся окно/**фильтр**.\n",
    "\n",
    "**Пулинг (pooling)** -- это схожая со скользящим окном техника, когда вместо свёртки по обучаемым весам к значениям в окне применяется некоторая статистическая функция (среднее, максимум, ...). Так, популярная механика тут -- это max pooling. Пулинг выполняет обобщение мелких деталей, устойчиво выделяет некоторый признак независимо от его размера и ориентации.\n",
    "\n",
    "**Канал** -- это множество фильтров, формирующих оригинальный двумерный вывод. Каналы нередко связываются с цветностью изображения.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "XVIF0OHjvkRW"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CifarModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CifarModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MoZi7iOLTDUH"
   },
   "source": [
    "Рассмотрим структуру этой модели подробнее.\n",
    "\n",
    "По мелким техническим причинам (необходимость выравнивания данных при переходе от свёрточных слоёв к линейным) её удобнее представить в формате классической модели, а не просто композицией слоёв.\n",
    "\n",
    "Первый слой -- Conv2d(3, 6, 5) с функцией активации ReLU создаёт набор свёрточных фильтров. Первый параметр 3 -- это количество входных каналов изображений, три цвета. Второй параметр 6 -- это количество выходных каналов, третий параметр -- размер фильтра 5x5. На выходе получается 6 фильтров размером 3x5x5 -- и всего модель выделяет (3 * 5 * 5 + 1) * 6 = 456 параметров.\n",
    "Выходной размер слоя получится 6 * 28 * 28 , где 28 = ((32 - 5) + 1)\n",
    "\n",
    "Метод MaxPool2d(2,2) -- это реализация max-пулинга (вычисление его аргументов см. по ссылке выше). kernel_size -- размер окна пулинга, stride -- шаг пулинга. Выходной размер слоя таким образом снижаем в два раза: с 6 * 28 * 28 до 6 * 14 * 14.\n",
    "\n",
    "\n",
    "Далее снова применяется функция Conv2d(6, 16, 5) -- шесть выходных каналов предыдущей функций как входы. Теперь мы применяем 16 фильтров (каждый размером 6 * 5 * 5), и выходной размер слоя будет 16 * 10 * 10, где 10 = (14 - 5) + 1. Всего на уровне обрабатывается (5 * 5 * 6 + 1) * 16 = 2416 параметров.\n",
    "\n",
    "Следующий max pooling снижает этот выход в два раза -- с 16 * 10 * 10 до 16 * 5 * 5.\n",
    "\n",
    "И в заключение добавляются три полносвязных слоя Linear. Обратите внимание, что перед ними надо выполнить модификацию структуры передаваемых данных, так как свёрточные слои работают с двумерными изображениями, а линейные -- с векторными наборами. Такое преобразование выполняет x.view(-1, 16 * 5 * 5).\n",
    "\n",
    "Первый линейный слой из 120 узлов, получает 16 * 5 * 5 входов -- то есть в нём требуется (16 * 5 * 5 + 1) * 120 = 48120 параметров, и далее количество входов-выходов понижается через следующие слои до наших итоговых 10 классов (последний уровень требует (84+1) * 10 = 850 параметров).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ZlW-CkjeOn2u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 loss=1.8027074337005615\n",
      "epoch=1 loss=0.9587485790252686\n"
     ]
    }
   ],
   "source": [
    "from torch import optim, nn\n",
    "\n",
    "model = CifarModel()\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        loss = train_step(images, labels)\n",
    "    print(f\"{epoch=} {loss=}\")\n",
    "\n",
    "# print(model.state_dict())\n",
    "# print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "L-zC19n5X_-7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность: 56.27 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # проверяем на тестовой выборке\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Точность: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56Kd4ku8b-9b"
   },
   "source": [
    "Считаем точность -- она получается в районе 55%. Это хороший результат, так как при случайном выборе мы получили бы 10%. Причём её можно существенно повысить -- уже после 10 эпох обучения мы получим точность 80+%!\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LX96AyHbcxSr"
   },
   "source": [
    "В заключение вычислим точность распознавания по каждому из признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5LzRkaZXxb9k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность для tensor(3) : 71 %\n",
      "Точность для tensor(5) : 83 %\n",
      "Точность для tensor(1) : 29 %\n",
      "Точность для tensor(7) : 52 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    print('Точность для %5s : %2d %%' % (\n",
    "        labels[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wVNjHoPddEUb"
   },
   "source": [
    "## **Задание.**\n",
    "Увеличение количества эпох (шагов обучения) существенно повышает качество модели. Но есть и другие способы -- поэкспериментируйте например с добавлением новых свёрточных или линейных слоёв, размерами фильтров и их количеством. В процессе экспериментов избегайте переобучения -- когда модель показывает отличные результаты на обучающей выборке, но невысокие на тестовой.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "В следующем занятии мы займёмся экспериментами с уже обученными моделями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 3*32*32   # Размер изображения в точках * количество цветов\n",
    "num_classes = 10       # Количество распознающихся классов (10 видов изображений)\n",
    "n_epochs = 10          # Количество эпох\n",
    "batch_size = 4         # Размер мини-пакета входных данных\n",
    "lr = 0.001             # Скорость обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "cifar_trainset = dsets.CIFAR10(root='./data', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "50000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "cifar_testset = dsets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "print(len(cifar_trainset))\n",
    "print(len(cifar_testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=cifar_trainset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=cifar_testset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# class CifarModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CifarModel, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 6, 5, padding=1)\n",
    "#         self.pool = nn.MaxPool2d(2, 2)\n",
    "#         self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "#         self.conv3 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "#         self.fc1 = nn.Linear(32 * 3 * 3, 128)\n",
    "#         self.fc2 = nn.Linear(128, 64)\n",
    "#         self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "#         x = self.pool(F.relu(self.conv3(x)))\n",
    "#         x = x.view(-1, 32 * 3 * 3)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CifarModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CifarModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 loss=0.8667067289352417\n",
      "epoch=1 loss=1.3581764698028564\n",
      "epoch=2 loss=0.5532975792884827\n",
      "epoch=3 loss=1.8869309425354004\n",
      "epoch=4 loss=1.5986688137054443\n",
      "epoch=5 loss=0.7259854078292847\n",
      "epoch=6 loss=1.1290162801742554\n",
      "epoch=7 loss=1.233428716659546\n",
      "epoch=8 loss=0.37808874249458313\n",
      "epoch=9 loss=1.1667022705078125\n"
     ]
    }
   ],
   "source": [
    "from torch import optim, nn\n",
    "\n",
    "model = CifarModel()\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        loss = train_step(images, labels)\n",
    "    print(f\"{epoch=} {loss=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность: 61.13 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # проверяем на тестовой выборке\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Точность: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность для tensor(3) : 74 %\n",
      "Точность для tensor(5) : 71 %\n",
      "Точность для tensor(1) : 47 %\n",
      "Точность для tensor(7) : 39 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    print('Точность для %5s : %2d %%' % (\n",
    "        labels[i], 100 * class_correct[i] / class_total[i]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "7ov4K97EJbu4"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
